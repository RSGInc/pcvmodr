#' Create annual truckload equivalents from FAF v4+ regional flow database
#'
#' @param faf_database Data frame containing the FAF regional full database in
#'   special format used by this package, created by import_faf_database() or
#'   comparable utility. The user can optionally provide the name (with path) of
#'   comma-separated value (CSV) file containing the data frame.
#' @param truck_allocaton_factors Data frame containing truck allocation
#'   factors, of a string with the filename of a CSV file containing them.
#' @param truck_equivalency_factors Data frame containing truck equivalency
#'   factors, or a string with the filename of a CSV file containing them.
#' @param empty_truck_factors Data frame containing empty truck factors, or a
#'   string with the filename of a CSV file containing them.
#' @param method The method used to map the tonnages to truckload equivalents
#'   can be specified. The method devised by Battelle for use with FAF version
#'   3.5 is the only one currently available.
#' @param target_year The four-digit simulation year as an integer value. The
#'   value must be one of the years in the FAF database, or fall within the
#'   interval x years before first year to x years after the time series in the
#'   FAF data, where x is the foreast_range_threshold.
#' @param forecast_range_threshold The number of years outside of the years
#'   included in the FAF database that will be mapped to those those years. The
#'   default is five years.
#' @param save_to File name for saving the annual truckload equivalents
#'   generated by this program. These data are sometimes saved to reduce run
#'   times for repeated runs of each simulation year, as well as in model
#'   development and testing.
#'
#' @details This function converts the commodity flows, measured in annual tons
#'   and value between FAF regions, into truckload equivalents. The five-step
#'   method described in the "FAF3 Freight Traffic Analysis" report is
#'   currently implemented, and the user should consult that documentation to
#'   understand the data requirements and methods used. The translation is
#'   deterministic, for it uses tables of proportions by vehicle type, body
#'   style, commodity, and trade type to arrive at one or more discrete annual
#'   truck trips by each of those indices, between each set of FAF regions that
#'   have commodity flows coded in the data. The result is a new, and much
#'   larger, data frame containing the number of truck trips for each inter-
#'   regional flow pair in the FAF data.
#'
#' @export
#' @examples
#' annual_trucks <- create_faf_annual_truckloads(faf_database,
#'  truck_allocation_factors, truck_equivalency_factors, empty_truck_factors,
#'  method = "Battelle", year = 2012)

create_faf_annual_truckloads <- function(faf_database, truck_allocation_factors,
  truck_equivalency_factors, empty_truck_factors, target_year,
  method = "battelle", forecast_range_threshold = 5, save_to = NULL) {
  # Irrespective of how we convert the commodity flows to truckload equivalents
  # we will need to select only the target year from the FAF database
   years_included <- sort(unique(faf_database$year))
   differences <- abs(years_included - target_year)
   closest_year <- years_included[which.min(differences)]

   # Check that the closest year is within the tolerances we've specified
   if (min(differences) > 0) {
     # Skip this part if the user selected a year included in the data
     if (min(differences) > forecast_range_threshold) {
       stop(paste("Target year", target_year, "exceeds range of FAF data"))
     } else {
       print(paste("Target year", target_year, "mapped to FAF year",
         closest_year), quote = FALSE)
     }
   }
   # And then grab only the exact or closest year, and only truck flows at that
   faf_database <- dplyr::filter(faf_database, year == closest_year,
     dms_mode == "Truck")

   # There are several records in the FAF data where value or tons (or both) are
   # coded as zero. Run a summary to show us how many of each are included in
   # the data. If the flow did not exist (i.e., was really zero) it wouldn't be
   # in the database in the first place.
   record_types <- dplyr::data_frame(seq = 1:4,
     record_type = c("Non-zero tons", "Non-zero value + zero tons",
       "Zero value & tons", "Missing value or tons"),
     action = c("Include as is", "Sample tons", "Sample both", "Drop record"))
   record_type_summary <- faf_database %>%
     dplyr::mutate(seq = ifelse(is.na(value) | is.na(tons), 4,
       ifelse(value >= 0.0 & tons > 0.0, 1,
         ifelse(value > 0.0 & tons == 0, 2, 3))))  %>%
     dplyr::group_by(seq, year, dms_mode) %>%
     dplyr::summarise(records = n()) %>%
     dplyr::ungroup() %>%
     dplyr::mutate(percent = round((records/sum(records))*100, 1)) %>%
     dplyr::left_join(record_types, by = "seq") %>%
     dplyr::select(year, dms_mode, record_type, records, percent, action)
   print(record_type_summary, quote = FALSE)

   # Pull out the records with non-zero tonnage and set them aside, under the
   # assumption that those data are robust.
   non_zeroes <- dplyr::filter(faf_database, value >= 0.0 & tons > 0.0)

   # Then pull out records with non-zero values but zero tons, which we'll sort
   # in descending order by value
   zero_tons <- faf_database %>%
     dplyr::filter(value >0 & tons == 0) %>%
     dplyr::arrange(value)
   if (nrow(zero_tons) > 0) {
     tonnage_draws <- sort(sample(1:1e3, nrow(zero_tons), replace = TRUE))
     zero_tons$tons <- tonnage_draws
   }

   # Finally, do the same for cases where both value and tonnage are missing,
   # although we'll need to change the logic a bit. First we'll sample value,
   # and then tonnage, matching both by descending order.
   zero_both <- dplyr::filter(faf_database, value == 0 & tons == 0)
   value_draws <- sort(sample(1:1e6, nrow(zero_both), replace = TRUE))
   tonnage_draws <- sort(sample(1:1e4, nrow(zero_both), replace = TRUE))
   zero_both$value <- value_draws
   zero_both$tons <- tonnage_draws

   # Now put them back together into single revised FAF database, which we will
   # sample the annual truckload equivalents from
   rev_faf_database <- dplyr::bind_rows(non_zeroes, zero_tons)
   rev_faf_database <- dplyr::bind_rows(rev_faf_database, zero_both)

   # Now call the appropriate function to map the data
   if (tolower(method) == "battelle") {
     results <- .battelle_solution(rev_faf_database, truck_allocation_factors,
       truck_equivalency_factors, empty_truck_factors)
   } else {
     stop(paste("Method", method, "is currently not implemented"))
   }

   # Return the results, but save the results to intermediate file before doing
   # so if requested by the user
   if (!is.null(save_to)) readr::write_csv(results, save_to)
   results
}

# This hidden function implements the process described in Battelle's 2013
# "Freight Traffic Analysis" report, developed as part of FAF version 3.5. The
# report has quietly dropped off of the FAF website (and the web in general, so
# far as I can tell). Until a newer/better process shows up we'll continue to
# use this in spite of our misgivings. We'll skip the roxygen2 header since this
# is an internal (hidden) function that users would not call directly. Indeed
# the only reason we isolate this code in separate function is to allow testing
# of different methods without disrupting working code.

.battelle_solution <- function(rev_faf_database, truck_allocation_factors,
  truck_equivalency_factors, empty_truck_factors) {
  print("Creating truckload equivalencies using Battelle FTA method",
    quote = FALSE)

  # Start by processing the truck allocation factos. If they are supplied as a
  # string assume it is a filename.
  if (!is.data.frame(truck_allocation_factors)) {
    print(paste("Reading truck allocation factors from",
      truck_allocation_factors), quote = FALSE)
    truck_allocation_factors <- readr::read_csv(truck_allocation_factors)
  }

  # Likewise define the truck equivalency factors, which must be converted from
  # wide to tall format before we can query them
  if (!is.data.frame(truck_equivalency_factors)) {
    print(paste("Reading truck equivalency factors from",
      truck_equivalency_factors), quote = FALSE)
    truck_equivalency_factors <- readr::read_csv(truck_equivalency_factors)
  }
  truck_equivalency_factors <- truck_equivalency_factors %>%
    tidyr::gather(body_type, equiv_factor, auto:other) %>%
    dplyr::filter(equiv_factor > 0.0)

  # Process the empty truck factors
  if (!is.data.frame(empty_truck_factors)) {
    print(paste("Reading empty truck factors from", empty_truck_factors),
      quote = FALSE)
    empty_truck_factors <- readr::read_csv(empty_truck_factors)
  }
  empty_truck_factors <- empty_truck_factors %>%
    tidyr::gather(vehicle_type, empty_factor, SU:TPT) %>%
    dplyr::filter(empty_factor > 0.0)

  # Most of the work in this function is isolated in a single function that we
  # can parallelize
  calc_truckload_equivalencies <- function(replicantID, replicant) {
    # Start by sampling the truck allocation factors for this commodity flow
    # replicant, which is defined by its distance range. The tonnage is
    # allocated to each vehicle class (as in Table 3-7). Note that we normalize
    # the allocation factors, which don't sum to unity in some cases.
    TAF <- truck_allocation_factors %>%
      dplyr::filter(replicant$distance >= minimum_range &
          replicant$distance <= maximum_range & allocation_factor > 0.0) %>%
      dplyr::mutate(allocation_factor = allocation_factor/sum(allocation_factor),
        tons = replicant$tons * allocation_factor)

    # We next grab the truck equivalency factors
    TEF <- truck_equivalency_factors %>%
      dplyr::filter(sctg2 == replicant$sctg2) %>%
      dplyr::select(-sctg2)  # Prevent name collision later on

    # Calculate the annual tonnage by vehicle type
    loaded <- TEF %>%
      dplyr::left_join(TAF, by = "vehicle_type") %>%
      dplyr::mutate(annual_trucks = tons * equiv_factor)

    # It is possible that we wind up with less than one truck using the FAF
    # factors, which we will always round up to one truck. If that happens
    # pick the vehicle and body type that has the highest number of them.
    zed <- sum(loaded$annual_trucks, na.rm = TRUE)
    if (zed<1.0) {
      loaded <- loaded[which.max(loaded$annual_trucks),] %>%
        dplyr::mutate(annual_trucks = 1.0)
    }

    # Next we append empty trucks, but they are differentiates between domestic
    # and cross-border. Thus, we'll first need to map the trade type from the
    # FAF data to these categories.
    replicant$crossing_type <-
      ifelse(tolower(replicant$trade_type) == "domestic", "domestic", "border")
    empties <- empty_truck_factors %>%
      dplyr::filter(replicant$crossing_type == crossing_type) %>%
      dplyr::full_join(loaded, by = c("body_type", "vehicle_type")) %>%
      dplyr::filter(!is.na(tons), !is.na(empty_factor)) %>%
      dplyr::mutate(empty_trucks = annual_trucks * empty_factor)

    # We needed to retain the body types to calculate empties, but now we
    # can collapse each group to vehicle types
    loaded <- loaded %>%
      dplyr::group_by(vehicle_type) %>%
      dplyr::summarise(annual_trucks = round(sum(annual_trucks), 0)) %>%
      mutate(status = "loaded")
    empties <- empties %>%
      dplyr::group_by(vehicle_type) %>%
      summarise(annual_trucks = round(sum(empty_trucks), 0)) %>%
      mutate(status = "empty")

    # Create a separate record for the combined groups and merge with the
    # data from the flow record. Note that we drop the original value and
    # tons, as they are now split among the various loaded truck types.
    loaded <- loaded %>%
      dplyr::mutate(percent = annual_trucks/sum(annual_trucks),
        tons = percent*replicant$tons, value = percent*replicant$value) %>%
      dplyr::select(-percent)
    empties <- dplyr::mutate(empties, tons = 0.0, value = 0.0)
    combined <- dplyr::bind_rows(loaded, empties) %>%
      dplyr::filter(annual_trucks > 0)

    # Add the SCTG code back in, as we will use that to merge the two tables.
    # However, we could have an edge case where zed>1 but we still wind up with
    # zero vehicles. So catch that here and send back an empty data frame.
    if (sum(combined$annual_trucks) < 1) {
      result <- dplyr::data_frame()
    } else {
      combined$sctg2 <- replicant$sctg2
      result <- dplyr::full_join(dplyr::select(replicant, -tons, -value),
        combined, by="sctg2")
      result$zed <- zed
    }

    # The status message will not print to console when running in parallel,
    # but can be added to the console log and reviewed later
    print(paste("replicantID", replicantID, ": records=", nrow(result),
      ", zed=", zed), quote = FALSE)
    result
  }   # end of calc_truckload_equivalencies()

  # With all of the preliminaries out of the way let's create the truckload
  # equivalencies. Each call to the function will return a data frame with zero
  # or more rows, by truck type and load status (i.e., loaded versus empty).
  parallel_start <- proc.time()
  result_list <- foreach(i=1:nrow(rev_faf_database),
    .packages=c("dplyr", "tidyr")) %dopar% {
      calc_truckload_equivalencies(i, rev_faf_database[i,])
    }
  results <- dplyr::bind_rows(result_list)   # Convert from list to data frame
  parallel_stop <- proc.time()
  elapsed_seconds <- round((parallel_stop - parallel_start)[["elapsed"]], 1)
  print(paste("Simulation time=", elapsed_seconds, "seconds"), quote=FALSE)
  print(paste(prettyNum(sum(results$annual_trucks), big.mark = ','),
    "annual truckload equivalents generated from",
    prettyNum(nrow(rev_faf_database), big.mark = ','),
    "commodity flow records"), quote = FALSE)

  # Return the results
  results
}
